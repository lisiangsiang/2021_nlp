{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencc import OpenCC\n",
    "import os\n",
    "import jieba\n",
    "import json\n",
    "\n",
    "cc = OpenCC('s2t')\n",
    "data_Path='/Users/chenlisiang/wiki_zh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_blank(word):\n",
    "    result=re.sub('\\W+',' ',word).replace(\"_\",'')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wf(Path):\n",
    "    for dirc in os.listdir(Path):\n",
    "        for dirlist in os.listdir(Path+\"/\"+dirc):\n",
    "            with open(\"wiki.txt\", 'a', encoding='utf-8') as new_f:\n",
    "                with open(Path+\"/\"+dirc+\"/\"+dirlist, 'r', newline='', encoding='utf-8') as file:\n",
    "                    for a,data in enumerate(file, 1):\n",
    "                        data = cc.convert(data)\n",
    "                        data = json.loads(data)\n",
    "                        data = replace_blank(data['text'])\n",
    "                        data = jieba.cut(data)\n",
    "                        data = [word for word in data if word != ' ']\n",
    "                        data = ' '.join(data)+\"\\n\"\n",
    "                        new_f.write(data)                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gensim, logging\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/h8/xtnqvm910v943k55rmpn3xj40000gn/T/jieba.cache\n",
      "Loading model cost 1.901 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "wf(data_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "seed = 666\n",
    "sg = 0\n",
    "window_size = 10\n",
    "vector_size = 100\n",
    "min_count = 1\n",
    "workers = 8\n",
    "epochs = 5\n",
    "batch_words = 10000\n",
    "train_data = word2vec.LineSentence('wiki.txt')\n",
    "#訓練\n",
    "model = word2vec.Word2Vec(\n",
    "    train_data,\n",
    "    min_count=min_count,\n",
    "    vector_size=vector_size,\n",
    "    workers=workers,\n",
    "    epochs=epochs,\n",
    "    window=window_size,\n",
    "    sg=sg,\n",
    "    seed=seed,\n",
    "    batch_words=batch_words\n",
    ")\n",
    "\n",
    "model.save('nlp_hw4.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('微生物', 0.8217324614524841)\n",
      "('生物所', 0.7666420936584473)\n",
      "('動物', 0.7569385170936584)\n",
      "('海洋生物', 0.7536638975143433)\n",
      "('細菌', 0.7400171160697937)\n",
      "('分子生物', 0.7356173992156982)\n",
      "('人類', 0.731623113155365)\n",
      "('藻類', 0.7290234565734863)\n",
      "('非生物', 0.7272068858146667)\n",
      "('古菌', 0.7253413796424866)\n",
      "('昆蟲', 0.7170726656913757)\n",
      "('態學', 0.7167205214500427)\n",
      "('線蟲', 0.7161225080490112)\n",
      "('靈長類', 0.7043749690055847)\n",
      "('硅藻', 0.7029224038124084)\n",
      "('遺傳學', 0.6996084451675415)\n",
      "('兩棲類', 0.6973147392272949)\n",
      "('綠藻', 0.692268967628479)\n",
      "('單細胞', 0.6919310092926025)\n",
      "('生物能', 0.6855676770210266)\n"
     ]
    }
   ],
   "source": [
    "for item in model.wv.most_similar('生物',topn=20):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('中學', 0.8008331656455994)\n",
      "('該校', 0.7857492566108704)\n",
      "('小學', 0.7606030106544495)\n",
      "('該學校', 0.7588860392570496)\n",
      "('女校', 0.7434068918228149)\n",
      "('這所學校', 0.7356535196304321)\n",
      "('夜校', 0.7311002612113953)\n",
      "('學校則', 0.7260481715202332)\n",
      "('新學校', 0.7254934906959534)\n",
      "('各學校', 0.7191322445869446)\n",
      "('校內', 0.7173876762390137)\n",
      "('師範學校', 0.7128761410713196)\n",
      "('學生', 0.7089331746101379)\n",
      "('女學校', 0.708842933177948)\n",
      "('班級', 0.708552896976471)\n",
      "('四年制', 0.7084717154502869)\n",
      "('中學以', 0.706771969795227)\n",
      "('兩所學校', 0.7040538191795349)\n",
      "('住校', 0.7039852738380432)\n",
      "('華中大學', 0.7015777826309204)\n"
     ]
    }
   ],
   "source": [
    "for item in model.wv.most_similar('學校',topn=20):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
